from typing import List, Dict, Any
# Import typing hints to specify the expected types of variables and function parameters/returns
# List: A list of items of a specific type
# Dict: A dictionary with keys and values of specific types
# Any: Can be any type

from openai import AsyncOpenAI
# Import the AsyncOpenAI client from the openai package
# This is the asynchronous version of the OpenAI client, which allows for non-blocking API calls

from base_agent import BaseAgent
# Import the BaseAgent abstract base class that defines the common interface for all agents

class OpenAIAgent(BaseAgent):
    """Agent for generating answers using OpenAI's GPT models."""
    # This class implements the BaseAgent interface for OpenAI's GPT models
    # It handles the specifics of communicating with the OpenAI API
    
    def __init__(self, api_key: str, model_name: str = "gpt-4"):
        """Initialize OpenAI agent with an API key and model name.
        
        Args:
            api_key (str): OpenAI API key
            model_name (str, optional): Model to use. Defaults to "gpt-4".
        """
        # Constructor method that runs when a new OpenAIAgent is created
        # Takes an API key and an optional model name
        
        super().__init__(api_key)
        # Call the parent class (BaseAgent) constructor with the API key
        # This will store the API key and validate it
        
        self.model_name = model_name
        # Store the model name as an instance variable
        
        self.client = AsyncOpenAI(api_key=api_key)
        # Create an AsyncOpenAI client with the provided API key
        # This client will be used to make API calls to OpenAI

    async def generate_answer(self, query: str, results: List[Dict[str, Any]]) -> str:
        """Generate a comprehensive answer from retrieved results using OpenAI.
        
        Args:
            query (str): The user's question
            results (List[Dict[str, Any]]): Retrieved results from Pinecone
            
        Returns:
            str: The generated answer
        """
        # Implementation of the abstract method from BaseAgent
        # This method generates an answer to the user's question based on the retrieved results
        # It's marked as async, which means it's an asynchronous method that can be awaited
        
        context = self.format_context(results)
        # Format the retrieved results into a context string using the method from BaseAgent
        
        try:
            # Try to generate an answer using the OpenAI API
            response = await self.client.chat.completions.create(
                # Make an asynchronous API call to create a chat completion
                model=self.model_name,
                # Specify which model to use (e.g., "gpt-4")
                messages=[
                    # Provide a list of messages that define the conversation
                    {
                        "role": "system",
                        # The system message sets the behavior of the assistant
                        "content": "You are a helpful assistant that provides comprehensive answers based on the retrieved information. Cite your sources when appropriate."
                        # This content tells the model to act as a helpful assistant and cite sources
                    },
                    {
                        "role": "user",
                        # The user message contains the user's question and the context
                        "content": f"Based on the following information, please provide a comprehensive answer to this question: '{query}'\n\nRetrieved Information:\n{context}"
                        # This content includes the user's question and the formatted context
                    }
                ]
            )
            # The API call returns a response object with the generated completion
            
            return response.choices[0].message.content
            # Extract the content of the first (and only) message in the response and return it
            # This is the actual answer generated by the model
            
        except Exception as e:
            # If there's an error during the API call
            print(f"Error generating answer with OpenAI: {e}")
            # Print the error message for debugging
            
            return "I couldn't generate an answer based on the retrieved information."
            # Return a fallback message to the user 